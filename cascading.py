# -*- coding: utf-8 -*-
"""lemidahishuvit2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17n9vbhro5Yp3PJEtjoxndABsN-FaaT1C

# Functions
"""

from google.colab import drive
drive.mount('/content/drive/')

import pandas as pd
import numpy as np
from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier
from sklearn.model_selection import train_test_split # Import train_test_split function
from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation
from sklearn.metrics import log_loss
import warnings
warnings.filterwarnings("ignore")
import matplotlib.pyplot as plt
import numpy as np

def fill_missing_values(df_to_fill):
    df_to_fill.dropna(how='all')
    df_to_fill = df_to_fill.apply(lambda x: x.fillna(x.mean()),axis=0)
    # print(df_to_fill)
    return df_to_fill

def convert_string_value_to_int(df_to_fill,mapping, cols):
  # mapping = {'set': 1, 'test': 2}
  for c in cols:
    df_to_fill = df_to_fill.replace({c: mapping})
  # print(df_to_fill)
  return df_to_fill

def convert_string_values_to_int(df_to_fill):
  col_df = list(df_to_fill.head(0))
  for c in col_df:
    data_of_c = df_to_fill[c]
    data_of_c = list(dict.fromkeys(data_of_c))
    # data_of_c.append(None)
    # data_of_c.append('')


    # print(len(data_of_c))
    # print(data_of_c)
    # print(c)
    data = df_to_fill.loc[:,c]
    # print(len(data))
    
    for d in data:
      # print(data_of_c.index(d))
      # if d==nan:
      #   print(c)
      try:
        df_to_fill.at[d,c] = data_of_c.index(d)
      except Exception as e:
        print(c)
        df_to_fill.at[d,c] = 0
  # print(df_to_fill)
  return df_to_fill

file = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/data/1_V_v/bank.csv')
print(file)
file = file.replace(np.nan,0)
file = convert_string_values_to_int(file)

file

def iteration(df_train, df_test, max_depth, label_column_name, features_columns_names, threshold=0.95):
    if(len(df_test)==0):
        return pd.DataFrame(), [] , [] , []

    # Create Decision Tree classifer object
    clf = DecisionTreeClassifier(max_depth=max_depth)

    X_train = df_train[features_columns_names]
    y_train = df_train[label_column_name]
    X_test = df_test[features_columns_names]
    y_test = df_test[label_column_name]

    # Train Decision Tree Classifer
    clf = clf.fit(X_train, y_train)

    # Predict the response for test dataset
    y_proba = clf.predict_proba(X_test)

    y_test = np.array(y_test)

    df_underThreshold = pd.DataFrame()
    y_underThreshold_test = []
    y_overThreshold_proba = []
    y_overThreshold_test = []

    i = 0
    for index, row in X_test.iterrows():
        if (np.max(y_proba[i]) > threshold):
            # for log-loss caclulation after 15 iterations
            y_overThreshold_proba.append(y_proba[i])
            y_overThreshold_test.append(y_test[i])
        else:
            df_underThreshold = df_underThreshold.append(row)
            y_underThreshold_test.append(y_test[i])

        i = i + 1
    return df_underThreshold, y_underThreshold_test, y_overThreshold_proba, y_overThreshold_test

def cascadingAlgorithm(label, columnsNames, X_train, y_train,X_test, y_test, max_iterations=15, threshold=0.95):
    X_train[label] = np.array(y_train).copy()
    X_test[label] = np.array(y_test).copy()
    df_train = X_train.copy()
    df_test = X_test.copy()

    #data for later caculation of log-loss metric
    final_y_overThreshold_proba = []
    final_y_overThreshold_test = []

    for j in range(1,max_iterations+1):
        df_underThreshold, y_underThreshold_test, y_overThreshold_proba, y_overThreshold_test = iteration(df_train, df_test, j,label,columnsNames, threshold)
        df_test = df_underThreshold
        df_test[label] = y_underThreshold_test
        final_y_overThreshold_proba.extend(y_overThreshold_proba)
        final_y_overThreshold_test.extend(y_overThreshold_test)

    evaluation = log_loss(final_y_overThreshold_test,final_y_overThreshold_proba)
    print("log-loss:",evaluation)
    return evaluation

def calculate_cascade(label, columnsNames, X_train, y_train,X_test, y_test):
  a = cascadingAlgorithm(label, columnsNames, X_train, y_train,X_test, y_test, 15, 0.95)
  b = cascadingAlgorithm(label, columnsNames, X_train, y_train,X_test, y_test, 20, 0.95)
  c = cascadingAlgorithm(label, columnsNames, X_train, y_train,X_test, y_test, 15, 0.98)
  return a,b,c

col_names = ['pregnant', 'glucose', 'bp', 'skin', 'insulin', 'bmi', 'pedigree', 'age', 'label']
# load dataset
#pima = pd.read_csv("../input/pima-indians-diabetes-database/diabetes.csv", header=0, names=col_names)
pima = pd.read_csv("/tmp/data/cosmetics.csv", header=0, names=col_names)

#split dataset in features and target variable
feature_cols = ['pregnant', 'insulin', 'bmi', 'age','glucose','bp','pedigree', 'skin']
X = pima[feature_cols] # Features
y = pima.label # Target variable

#plot
def get_graph(y,title):
  x = np.array(['basic', "improved 1", "improved 2"])
  plt.bar(x,y)
  plt.title(title)
  plt.show()

"""# /1_V_v/bank.csv

"""

file = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/data/1_V_v/bank.csv')
col_names = list(file.head(0))
pima = pd.read_csv("/content/drive/MyDrive/Colab Notebooks/data/1_V_v/bank.csv", header=0, names=col_names)
# pima = fill_missing_values(pima)

pima = pd.get_dummies(pima)
pima.head()

pima = fill_missing_values(pima)

pima = pima.head(20000)

print("pima.first:")
print(list(pima.columns.values))

print(pima)
#split dataset in features and target variable
feature_cols =  list(pima.columns.values)
feature_cols.remove('day')
X = pima[feature_cols] # Features
y = pima.day # Target variable

# Split dataset into training set and test set
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1) # 70% training and 30% test

label = 'day'
columnsNames = feature_cols

a,b,c = calculate_cascade(label, columnsNames, X_train, y_train,X_test, y_test)

y = [a, b, c]
get_graph(y,'bank')

cascadingAlgorithm(label, columnsNames, X_train, y_train,X_test, y_test, 15, 0.98)

"""# 2/Placement_Data_Full_Class.csv"""

file = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/data/2_V_v/Placement_Data_Full_Class.csv')
col_names = list(file.head(0))
pima = pd.read_csv("/content/drive/MyDrive/Colab Notebooks/data/2_V_v/Placement_Data_Full_Class.csv", header=0, names=col_names)
# pima = fill_missing_values(pima)
mapping = {'Others': 1, 'Central': 2}
cols = ['ssc_b', 'hsc_b']
pima = convert_string_value_to_int(pima,mapping, cols)
mapping = {'M': 1, 'F': 2}
cols = ['gender']
pima = convert_string_value_to_int(pima,mapping, cols)
mapping = {'Commerce': 1, 'Science': 2, 'Arts':3}
cols = ['hsc_s']
pima = convert_string_value_to_int(pima,mapping, cols)
mapping = {'Sci&Tech': 1, 'Comm&Mgmt': 2}
cols = ['degree_t']
pima = convert_string_value_to_int(pima,mapping, cols)
mapping = {'No': 1, 'Yes': 2}
cols = ['workex']
pima = convert_string_value_to_int(pima,mapping, cols)
mapping = {'Mkt&HR': 1, 'Mkt&Fin': 2}
cols = ['specialisation']
pima = convert_string_value_to_int(pima,mapping, cols)
mapping = {'Placed': 1, 'Not Placed': 2}
cols = ['status']
pima = convert_string_value_to_int(pima,mapping, cols)

mapping = {None: 0}
cols = ['salary']
pima = convert_string_value_to_int(pima,mapping, cols)

pima = pd.get_dummies(pima)
pima.head()


# pima = fill_missing_values(pima)

print(list(pima.columns.values))

feature_cols = list(pima.columns.values)
feature_cols.remove('gender')
print(feature_cols)
#split dataset in features and target variable
# feature_cols =  ['gender','ssc_p','ssc_b','hsc_p','hsc_b','hsc_s','degree_p','degree_t','workex','etest_p','specialisation','mba_p','salary']
X = pima[feature_cols] # Features
y = pima.gender # Target variable

print(pima)

# Split dataset into training set and test set
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1) # 70% training and 30% test

label = 'gender'
columnsNames = feature_cols

a,b,c = calculate_cascade(label, columnsNames, X_train, y_train,X_test, y_test)

y = np.array([a, b, c])
get_graph(y,'2_V_v/Placement_Data_Full_Class' )

"""# /tmp/data/3/water_potability.csv"""

col_names = ['ph','Hardness','Solids','Chloramines','Sulfate','Conductivity','Organic_carbon','Trihalomethanes','Turbidity','Potability']
# load dataset
#pima = pd.read_csv("../input/pima-indians-diabetes-database/diabetes.csv", header=0, names=col_names)
pima = pd.read_csv("/content/drive/MyDrive/Colab Notebooks/data/3_V_v/water_potability.csv", header=0, names=col_names)
pima = fill_missing_values(pima)

#split dataset in features and target variable
feature_cols =  ['ph','Hardness','Solids','Chloramines','Sulfate','Conductivity','Organic_carbon','Trihalomethanes','Turbidity']
X = pima[feature_cols] # Features
y = pima.Potability # Target variable

# Split dataset into training set and test set
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1) # 70% training and 30% test

label = 'Potability'
columnsNames = ['ph','Hardness','Solids','Chloramines','Sulfate','Conductivity','Organic_carbon','Trihalomethanes','Turbidity']

a,b,c = calculate_cascade(label, columnsNames, X_train, y_train,X_test, y_test)

y = [a, b, c]
get_graph(y,'water_potabilitys' )

"""# /4_V/cosmetics.csv"""

file = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/data/4_V/cosmetics.csv')
col_names = list(file.head(0))
pima = pd.read_csv("/content/drive/MyDrive/Colab Notebooks/data/4_V/cosmetics.csv", header=0, names=col_names)



# pima =pima.head(2000)

# mapping = {None: 0}
# cols = ['building_floor_count']
# pima = convert_string_value_to_int(pima,mapping, cols)

print(pima)
pima = pd.get_dummies(pima)

print("pima.first:")
print(list(pima.columns.values))

print(pima)

#split dataset in features and target variable
feature_cols = list(pima.columns.values)
feature_cols.remove('Normal')
# feature_cols = ['Brand','Name','Price','Rank','Ingredients','Combination','Dry','Normal','Oily','Sensitive']
X = pima[feature_cols] # Features
y = pima.Normal # Target variable

# Split dataset into training set and test set
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1) # 70% training and 30% test

label = 'Normal'
columnsNames = feature_cols

X_train

a,b,c = calculate_cascade(label, columnsNames, X_train, y_train,X_test, y_test)

y = np.array([a, b, c])
get_graph(y,'cosmetics' )

"""# /tmp/data/5/customer_data.csv"""

file = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/data/5_V/customer_data.csv')
col_names = list(file.head(0))
pima = pd.read_csv("/content/drive/MyDrive/Colab Notebooks/data/5_V/customer_data.csv", header=0, names=col_names)
pima = fill_missing_values(pima)

pima = fill_missing_values(pima)

pima = pd.get_dummies(pima)
pima.head()

print(pima)

print("pima.first:")
print(list(pima.columns.values))

#split dataset in features and target variable
feature_cols =  list(pima.columns.values)
feature_cols.remove('label')
X = pima[feature_cols] # Features
y = pima.label # Target variable

# Split dataset into training set and test set
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1) # 70% training and 30% test

label = 'label'
columnsNames = ['fea_1','fea_2','fea_3','fea_4','fea_5','fea_6','fea_7','fea_8','fea_9','fea_10','fea_11']

a,b,c = calculate_cascade(label, columnsNames, X_train, y_train,X_test, y_test)

y = np.array([a, b, c])
get_graph(y,'customer_data' )

"""# /tmp/6/csgo_round_snapshots.csv"""

file = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/data/6_V/csgo_round_snapshots.csv')
col_names = list(file.head(0))
pima = pd.read_csv("/content/drive/MyDrive/Colab Notebooks/data/6_V/csgo_round_snapshots.csv", header=0, names=col_names)
# pima = fill_missing_values(pima)



pima = pd.get_dummies(pima)
pima.head()

pima = fill_missing_values(pima)

pima = pima.head(2000)

print(pima)

print("pima.first:")
print(list(pima.columns.values))

#split dataset in features and target variable
feature_cols =  list(pima.columns.values)
feature_cols.remove('ct_score')
X = pima[feature_cols] # Features
y = pima.ct_score # Target variable

# Split dataset into training set and test set
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1) # 70% training and 30% test

label = 'ct_score'
columnsNames = feature_cols

a,b,c = calculate_cascade(label, columnsNames, X_train, y_train,X_test, y_test)

y = np.array([a, b, c])
get_graph(y,'csgo_round_snapshots' )

"""# /7_V/Classification of Robots from their conversation sequence.csv"""

file = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/data/7_V/Classification of Robots from their conversation sequence.csv')
col_names = list(file.head(0))
pima = pd.read_csv("/content/drive/MyDrive/Colab Notebooks/data/7_V/Classification of Robots from their conversation sequence.csv", header=0, names=col_names)
# pima = fill_missing_values(pima)



pima = pd.get_dummies(pima)
pima.head()

pima = fill_missing_values(pima)

print(pima)

pima = pima.head(2000)

print("pima.first:")
print(list(pima.columns.values))

#split dataset in features and target variable
feature_cols =  list(pima.columns.values)
feature_cols.remove('source')
X = pima[feature_cols] # Features
y = pima.source # Target variable

# Split dataset into training set and test set
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1) # 70% training and 30% test

label = 'source'
columnsNames = feature_cols

a,b,c = calculate_cascade(label, columnsNames, X_train, y_train,X_test, y_test)

y = np.array([a, b, c])
get_graph(y,'Classification of Robots from their conversation sequence' )

"""# /8_V/income_evaluation.csv"""

file = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/data/8_V/healthcare-dataset-stroke-data.csv')
col_names = list(file.head(0))
pima = pd.read_csv("/content/drive/MyDrive/Colab Notebooks/data/8_V/healthcare-dataset-stroke-data.csv", header=0, names=col_names)
# pima = fill_missing_values(pima)

pima = pd.get_dummies(pima)
pima.head()

pima = fill_missing_values(pima)


# pima = pima.head(5000)

print("pima.first:")
print(list(pima.columns.values))

print(pima)
#split dataset in features and target variable
feature_cols =  list(pima.columns.values)

feature_cols.remove('stroke')
X = pima[feature_cols] # Features
y = pima['stroke'] # Target variable

# Split dataset into training set and test set
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1) # 70% training and 30% test

label = 'stroke'
columnsNames = feature_cols

a,b,c = calculate_cascade(label, columnsNames, X_train, y_train,X_test, y_test)

y = np.array([a, b, c])
get_graph(y,'healthcare-dataset-stroke-data' )

"""# /9_V/spambase_csv.csv"""

file = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/data/9_V/spambase_csv.csv')
col_names = list(file.head(0))
pima = pd.read_csv("/content/drive/MyDrive/Colab Notebooks/data/9_V/spambase_csv.csv", header=0, names=col_names)
# pima = fill_missing_values(pima)



pima = pd.get_dummies(pima)
pima.head()

pima = fill_missing_values(pima)



# pima = pima.head(2000)

print("pima.first:")
print(list(pima.columns.values))

print(pima)
#split dataset in features and target variable
feature_cols =  list(pima.columns.values)
f = 'age'
feature_cols.remove('class')
X = pima[feature_cols] # Features
y = pima['class'] # Target variable

# Split dataset into training set and test set
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1) # 70% training and 30% test

label = 'class'
columnsNames = feature_cols

a,b,c = calculate_cascade(label, columnsNames, X_train, y_train,X_test, y_test)

y = np.array([a, b, c])
get_graph(y,'spambase' )

"""# /10_V/gamespot_game_reviews.csv"""

file = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/data/10_V/Dry_Bean.csv')
col_names = list(file.head(0))
pima = pd.read_csv("/content/drive/MyDrive/Colab Notebooks/data/10_V/Dry_Bean.csv", header=0, names=col_names)
# pima = fill_missing_values(pima)

# pima = pd.get_dummies(pima)
# pima.head()

# pima = pd.get_dummies(pima, prefix=['SEKER', 'DERMASON', 'SIRA', 'HOROZ','CALI','BOMBAY','BARBUNYA'], columns=['Class'])
# pima.columns

mapping = {'SEKER': 1, 'DERMASON': 2, 'SIRA': 3,
           'HOROZ': 4, 'CALI': 5, 
           'BOMBAY': 6, 'BARBUNYA': 7}
cols = ['Class']
pima = convert_string_value_to_int(pima,mapping, cols)

pima = fill_missing_values(pima)


# pima = pima.head(2000)

print("pima.first:")
print(list(pima.columns.values))

print(pima)
#split dataset in features and target variable
feature_cols =  list(pima.columns.values)
f = 'age'
feature_cols.remove('Class')
X = pima[feature_cols] # Features
y = pima.Class # Target variable

# Split dataset into training set and test set
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1) # 70% training and 30% test

label = 'Class'
columnsNames = feature_cols

a,b,c = calculate_cascade(label, columnsNames, X_train, y_train,X_test, y_test)

y = np.array([a, b, c])
get_graph(y,'Dry_Bean' )